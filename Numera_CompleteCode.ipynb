{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q opencv-python matplotlib langchain langchain-together nest-asyncio langchain_community google-generativeai wolframalpha\n"
      ],
      "metadata": {
        "id": "P5o3_634US4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eacde4fe-14fa-4ecf-f6de-f07d63395080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.5/383.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF-08I7xT0v0"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import auth\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import time\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_together import ChatTogether\n",
        "\n",
        "from langchain_community.agent_toolkits.load_tools import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from IPython.display import Markdown\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['WOLFRAM_ALPHA_APPID'] = userdata.get('WOLFRAM_ALPHA_APPID')\n",
        "os.environ['TOGETHER_API_KEY'] = userdata.get('TOGETHER_API_KEY')"
      ],
      "metadata": {
        "id": "Fjbc0MC_X5xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "OcotOEP4U7Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/math_test2.jpg\"\n",
        "\n",
        "# Upload the file from local storage\n",
        "sample_file = genai.upload_file(path=image_path,\n",
        "                                display_name=\"math_test2\")\n",
        "\n",
        "# Print confirmation message with file details\n",
        "print(f\"Uploaded file '{sample_file.display_name}' as: {sample_file.uri}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "t0bJphUMY4QE",
        "outputId": "e62815c8-6c2c-42dc-b5de-7af6439e2b11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded file 'math_test2' as: https://generativelanguage.googleapis.com/v1beta/files/7p3zfcn4gm5u\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Prompt the model with text and the previously uploaded image.\n",
        "response = model.generate_content([sample_file, \"The given image will contain a math question, i need the question in text format.\"])\n",
        "\n",
        "Markdown(\">\" + response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "id": "WQHHfjveZGK0",
        "outputId": "1eb954dc-bc11-4c9e-e2d5-286d7a72e873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">Solve:\n$x^2+y^2=2$\n$x^2-y^2=1$"
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Math_prompt = response.text"
      ],
      "metadata": {
        "id": "ZWhLvp1fZNGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Together.ai model\n",
        "together_model = ChatTogether(model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\")"
      ],
      "metadata": {
        "id": "GyGRLBX5VeFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"wolfram-alpha\"], llm=together_model)\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=together_model,\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")"
      ],
      "metadata": {
        "id": "yOg16JPnV14k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\":\n",
        "    \"\"\"\n",
        "   Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "wolfram_alpha - A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query.\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "   Action: Decide on the action to take, typically using [wolfram_alpha].\n",
        "   Action Input: Provide the input query to the tool.\n",
        "   Observation: Record the result or response from the tool.\n",
        "   Thought: Reflect on the result and whether it solves the question. If it solves the question, return the answer. Else decide if another action is needed.\n",
        "   Final Answer: Provide the final answer to the original question if the solution has been found.\n",
        "\n",
        "   **Rules**:\n",
        "   1. After each observation, check if the problem has been solved to avoid unnecessary tool use.\n",
        "   2. Stop taking actions once the solution is found.\n",
        "   3. If the tool's response is unclear or incomplete, use your reasoning or take another action.\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "Thought:{agent_scratchpad}\n",
        "    \"\"\"\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": {Math_prompt}},\n",
        "]"
      ],
      "metadata": {
        "id": "OUDe6gXmXNuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent.invoke(Math_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nJIrpwGXRxP",
        "outputId": "3d762e94-abfc-4f9e-8f80-6927e36de6fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The given equations are a system of two quadratic equations with two variables, x and y. To solve for x and y, I can use the method of substitution or elimination. However, I can also use a more straightforward approach by adding and subtracting the equations to eliminate one variable.\n",
            "\n",
            "Action: wolfram_alpha\n",
            "Action Input: solve x^2 + y^2 = 2, x^2 - y^2 = 1\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAssumption: solve x^2 + y^2 = 2\n",
            "x^2 - y^2 = 1 \n",
            "Answer: x = -sqrt(3/2) and y = ± 1/sqrt(2)\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: The Wolfram Alpha output provides two possible values for x and y. However, I should also consider the other possible solution for x.\n",
            "\n",
            "Action: wolfram_alpha\n",
            "Action Input: solve x^2 + y^2 = 2, x^2 - y^2 = 1\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAssumption: solve x^2 + y^2 = 2\n",
            "x^2 - y^2 = 1 \n",
            "Answer: x = -sqrt(3/2) and y = ± 1/sqrt(2)\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mAction: wolfram_alpha\n",
            "Action Input: solve x^2 + y^2 = 2, x^2 - y^2 = 1, x = sqrt(3/2)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAssumption: solve x^2 + y^2 = 2\n",
            "x^2 - y^2 = 1\n",
            "x = sqrt(3/2) \n",
            "Answer: y = -1/sqrt(2)\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: The solutions to the system of equations are (x, y) = (-√(3/2), ±1/√2) and (x, y) = (√(3/2), -1/√2).\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "explanation_prompt_template = PromptTemplate(\n",
        "    input_variables=['solution', 'input_prompt'],\n",
        "    template=\"\"\"\n",
        "        Based on the solution and the input prompt provided: {solution}, {input_prompt} give a concise but detailed step-by-step explanation for the solution obtained.\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "MZejiU3AXUCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explanation_chain = LLMChain(llm=together_model, prompt=explanation_prompt_template)\n",
        "\n",
        "detailed_explanation = explanation_chain.run(solution=result, input_prompt= Math_prompt)\n",
        "\n",
        "for char in detailed_explanation:\n",
        "    print(char, end='', flush=True)\n",
        "    time.sleep(0.01)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW0y6_H6Xbm_",
        "outputId": "8d6a5016-fe19-496f-8e95-748f41efd7c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-889338577fcb>:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  explanation_chain = LLMChain(llm=together_model, prompt=explanation_prompt_template)\n",
            "<ipython-input-18-889338577fcb>:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  detailed_explanation = explanation_chain.run(solution=result, input_prompt= Math_prompt)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To solve the given system of equations, we can follow these steps:\n",
            "\n",
            "1. Subtract the second equation from the first equation to eliminate x^2:\n",
            "   $x^2+y^2=2$\n",
            "   $x^2-y^2=1$\n",
            "   Subtracting, we get: \n",
            "   $(x^2+y^2)-(x^2-y^2)=2-1$\n",
            "   This simplifies to:\n",
            "   $2y^2=1$\n",
            "   Divide both sides by 2:\n",
            "   $y^2=1/2$\n",
            "   Take the square root of both sides:\n",
            "   $y=±1/√2$\n",
            "\n",
            "2. Now that we have the values of y, we can substitute them into either of the original equations to solve for x. We will use the first equation:\n",
            "   $x^2+y^2=2$\n",
            "   Substitute y=±1/√2:\n",
            "   $x^2+(±1/√2)^2=2$\n",
            "   Simplify the equation:\n",
            "   $x^2+(1/2)=2$\n",
            "   Subtract 1/2 from both sides:\n",
            "   $x^2=3/2$\n",
            "   Take the square root of both sides:\n",
            "   $x=±√(3/2)$\n",
            "\n",
            "3. Now that we have the values of x and y, we can pair them up to get the solutions to the system of equations. \n",
            "   If y=±1/√2 and x=±√(3/2), then we must ensure the signs are consistent with the original equations. \n",
            "   For y=1/√2, x=√(3/2) does not satisfy the second equation, so we discard it. \n",
            "   For y=-1/√2, x=√(3/2) does satisfy the second equation.\n",
            "   For y=1/√2, x=-√(3/2) does satisfy the second equation.\n",
            "   For y=-1/√2, x=-√(3/2) does not satisfy the second equation, so we discard it.\n",
            "\n",
            "Therefore, the solutions to the system of equations are (x, y) = (-√(3/2), ±1/√2) and (x, y) = (√(3/2), -1/√2)\n"
          ]
        }
      ]
    }
  ]
}